{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Fashion Mnist datasets classification from Kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator \n",
    "import re\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "#fashion_mnist = fetch_openml(name=\"Fashion-MNIST\")\n",
    "DATA_PATH=\"/pscratch/sd/l/luckow/data/qml/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract labels\n",
    "# mnist_labels = fashion_mnist.target.astype(int)\n",
    "\n",
    "# # Class names for Fashion MNIST\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# # Print the first few labels and their corresponding class names\n",
    "# for i in range(5):\n",
    "#     print(f\"IDX: {i},  Label: {mnist_labels[i]} - Class: {class_names[mnist_labels[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Label: 9 - Class: Ankle boot\n",
      "Index: 1, Label: 0 - Class: T-shirt/top\n",
      "Index: 2, Label: 0 - Class: T-shirt/top\n",
      "Index: 3, Label: 3 - Class: Dress\n",
      "Index: 4, Label: 0 - Class: T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the Fashion MNIST labels file\n",
    "labels_path = os.path.join(DATA_PATH, \"train-labels-idx1-ubyte.gz\")\n",
    "# Class names for Fashion MNIST\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "def read_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as file:\n",
    "        # Read the magic number and number of labels\n",
    "        magic, num_labels = struct.unpack(\">II\", file.read(8))\n",
    "        # Read the labels\n",
    "        labels = struct.unpack(f'>{num_labels}B', file.read(num_labels))\n",
    "    return labels\n",
    "\n",
    "# Read labels from the file\n",
    "mnist_labels = read_labels(labels_path)\n",
    "\n",
    "\n",
    "# Optionally, print the first few labels with their class names\n",
    "for i in range(5):\n",
    "    print(f\"Index: {i}, Label: {mnist_labels[i]} - Class: {class_names[mnist_labels[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/60000 [00:00<1:37:26, 10.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [35:48<00:00, 27.92it/s]  \n",
      "100%|██████████| 10000/10000 [06:04<00:00, 27.41it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_train_data(qasm_files_path):\n",
    "    # Get the list of QASM files in the directory\n",
    "    qasm_files = [f for f in os.listdir(qasm_files_path) if f.endswith('.qasm')]\n",
    "\n",
    "    # Prepare data and labels\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    # Use the Aer simulator backend\n",
    "    backend = AerSimulator()\n",
    "\n",
    "    for qasm_file in tqdm(qasm_files):\n",
    "        file_path = os.path.join(qasm_files_path, qasm_file)\n",
    "        \n",
    "        # Read the QASM file\n",
    "        with open(file_path, 'r') as file:\n",
    "            qasm_code = file.read()\n",
    "        \n",
    "        # Create a QuantumCircuit from the QASM code\n",
    "        circuit = QuantumCircuit.from_qasm_str(qasm_code)\n",
    "        circuit.measure_all()\n",
    "\n",
    "        # Execute the circuit\n",
    "        job = backend.run(circuit, shots=8192*2)\n",
    "        \n",
    "        # Get the results\n",
    "        result = job.result()\n",
    "        counts = result.get_counts()\n",
    "        \n",
    "        #print(f'Results for {qasm_file}: {counts}')\n",
    "\n",
    "        # Convert counts to a fixed-length feature vector\n",
    "        # Assuming the circuits have at most 11 qubits\n",
    "        vector_length = 2**11\n",
    "        feature_vector = np.zeros(vector_length)\n",
    "        for state, count in counts.items():\n",
    "            index = int(state, 2)\n",
    "            feature_vector[index] = count\n",
    "        \n",
    "        train_data.append(feature_vector)\n",
    "        \n",
    "        # lookup label using the mnist-fashing index encoded in the filename \n",
    "        # Define the regular expression pattern to extract the number\n",
    "        pattern = r'_(\\d+)\\.qasm'\n",
    "        # Search for the pattern in the filename\n",
    "        match = re.search(pattern, qasm_file)\n",
    "\n",
    "        # Extract the number from the match object\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            #print(number)  # Output: 58659\n",
    "            label = mnist_labels[number]\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            print(\"No match found\")\n",
    "\n",
    "    return train_data, train_labels\n",
    "\n",
    "    \n",
    "QASM_TRAIN_CIRCUIT_PATH=os.path.join(DATA_PATH, \"train_general_3\")\n",
    "QASM_TEST_CIRCUIT_PATH=os.path.join(DATA_PATH, \"test_general_3\")\n",
    "\n",
    "train_data, train_labels = create_train_data(QASM_TRAIN_CIRCUIT_PATH)\n",
    "test_data, test_labels = create_train_data(QASM_TEST_CIRCUIT_PATH)\n",
    "\n",
    "# Combine training and test data\n",
    "all_data = train_data + test_data\n",
    "all_labels = train_labels + test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_data.npy', all_data)\n",
    "np.save('all_labels.npy', all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train different Classifiers\n",
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 2048)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the data from disk\n",
    "all_data = np.load('all_data.npy')\n",
    "all_labels = np.load('all_labels.npy')\n",
    "\n",
    "# Print shapes to verify\n",
    "print(all_data.shape)  # Should print (1000, 2048) or the shape of your actual data\n",
    "print(all_labels.shape)  # Should print (1000,) or the shape of your actual labels\n",
    "\n",
    "# Convert data and labels to numpy arrays\n",
    "data = np.array(all_data)\n",
    "labels = np.array(all_labels)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.19      0.21       706\n",
      "           1       0.26      0.33      0.29       737\n",
      "           2       0.18      0.16      0.17       680\n",
      "           3       0.22      0.21      0.21       701\n",
      "           4       0.20      0.21      0.21       739\n",
      "           5       0.21      0.20      0.20       674\n",
      "           6       0.18      0.12      0.14       680\n",
      "           7       0.37      0.52      0.43       685\n",
      "           8       0.34      0.26      0.29       691\n",
      "           9       0.32      0.38      0.35       707\n",
      "\n",
      "    accuracy                           0.26      7000\n",
      "   macro avg       0.25      0.26      0.25      7000\n",
      "weighted avg       0.25      0.26      0.25      7000\n",
      "\n",
      "Accuracy: 0.25842857142857145\n"
     ]
    }
   ],
   "source": [
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomial kernel SVM\n",
    "svm = SVC(kernel='poly', degree=2, gamma=1, coef0=0)\n",
    "\n",
    "# Use one-vs-rest strategy\n",
    "ovr_svm = OneVsRestClassifier(svm)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "#param_grid = {'estimator__C': [0.1, 1, 10, 100]}  # Regularization constants to try\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(ovr_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best regularization constant: {grid_search.best_params_}')\n",
    "print(f'Accuracy on test data: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Classifier with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomial kernel SVM\n",
    "svm = SVC(kernel='poly', degree=2, gamma=1, coef0=0)\n",
    "# classifier = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
    "\n",
    "# Use one-vs-rest strategy\n",
    "ovr_svm = OneVsRestClassifier(svm)\n",
    "\n",
    "ovr_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.16      0.18       706\n",
      "           1       0.26      0.31      0.28       737\n",
      "           2       0.17      0.19      0.18       680\n",
      "           3       0.20      0.20      0.20       701\n",
      "           4       0.18      0.14      0.16       739\n",
      "           5       0.20      0.20      0.20       674\n",
      "           6       0.18      0.20      0.19       680\n",
      "           7       0.37      0.42      0.40       685\n",
      "           8       0.31      0.31      0.31       691\n",
      "           9       0.35      0.32      0.33       707\n",
      "\n",
      "    accuracy                           0.24      7000\n",
      "   macro avg       0.24      0.24      0.24      7000\n",
      "weighted avg       0.24      0.24      0.24      7000\n",
      "\n",
      "Accuracy: 0.24442857142857144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the MLP classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), max_iter=300, solver='adam', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
